{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-scope",
   "metadata": {},
   "source": [
    "# Univariate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "combined-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "armed-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "\n",
    "        # De 0 Ã  8\n",
    "        if end_ix > len(sequence) -1:\n",
    "            break\n",
    "        \n",
    "        seq_x , seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rational-blocking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) (6,)\n",
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n"
     ]
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "n_steps = 3\n",
    "\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "concrete-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many time series in parallel?\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-bride",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "biblical-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(50, activation=\"relu\", input_shape=(n_steps, n_features)),\n",
    "    keras.layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alpha-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data into 3 dim\n",
    "X = X.reshape(X.shape[0], X.shape[1], n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinct-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xcb98b330f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "strange-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.2485]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-medium",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continental-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(50, activation=\"relu\", return_sequences=True, input_shape=(n_steps, n_features)),\n",
    "    keras.layers.LSTM(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "central-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xcb9d17ebe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit stacked lstm\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "czech-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.94471]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-single",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "senior-messaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(50, activation=\"relu\"), input_shape=(n_steps, n_features)),\n",
    "    keras.layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "million-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xcba181e6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit bidirectional lstm\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "forty-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.57055]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-american",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tired-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of stime steps\n",
    "n_steps = 4\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, subtimesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_substeps = 2\n",
    "\n",
    "X = X.reshape(X.shape[0], n_seq, n_substeps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "informal-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input cnn model\n",
    "# This can be achieved by wrapping the entire CNN model in a TimeDistributed wrapper that\n",
    "# will apply the entire model once per input, in this case, once per input subsequence.\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "                                       input_shape=(None, n_substeps, n_features)))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling1D(pool_size=2)))   \n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southeast-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output model\n",
    "model.add(keras.layers.LSTM(50, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "major-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xcba45c9908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit hybrid cnn-lstm\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "underlying-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107.40256]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape(1, n_seq, n_substeps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-corner",
   "metadata": {},
   "source": [
    "## ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "impressive-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of stime steps\n",
    "n_steps = 4\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_substeps = 2\n",
    "\n",
    "X = X.reshape(X.shape[0], n_seq, 1, n_substeps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "postal-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_substeps, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "elementary-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BastOS\\anaconda3\\envs\\timeseries\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcb98b54f28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proof-badge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103.86982]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape(1, n_seq, 1, n_substeps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-setting",
   "metadata": {},
   "source": [
    "# Multivariate LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-consciousness",
   "metadata": {},
   "source": [
    "## Multiple Input Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "damaged-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, cols] structure\n",
    "in_seq1 = in_seq1.reshape(in_seq1.shape[0], 1)\n",
    "in_seq2 = in_seq2.reshape(in_seq2.shape[0], 1)\n",
    "out_seq = out_seq.reshape(out_seq.shape[0], 1)\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "automotive-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "higher-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2) (7,)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "n_steps = 3\n",
    "\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "supposed-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "static-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "personal-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcba94a6a58>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "narrow-electricity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[206.2151]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-verse",
   "metadata": {},
   "source": [
    "## Multiple Parallel Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "magnetic-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, cols] structure\n",
    "in_seq1 = in_seq1.reshape(in_seq1.shape[0], 1)\n",
    "in_seq2 = in_seq2.reshape(in_seq2.shape[0], 1)\n",
    "out_seq = out_seq.reshape(out_seq.shape[0], 1)\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "apparent-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "comparable-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 3) (6, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [40 45 85]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [ 50  55 105]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [ 60  65 125]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [ 70  75 145]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [ 80  85 165]\n",
      "[[ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]] [ 90  95 185]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 3\n",
    "\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "loving-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interesting-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation=\"relu\"))\n",
    "model.add(Dense(n_features))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hourly-america",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbad9c1b70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "declared-portuguese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(1, 3, 3)\n",
      "[[100.3972   105.633896 205.67896 ]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([[70, 75, 145], [80, 85, 165], [90, 95, 185]])\n",
    "print(x_input.shape)\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "print(x_input.shape)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-wheat",
   "metadata": {},
   "source": [
    "# Multi-step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "operating-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_ix = end_ix + n_steps_out\n",
    "        \n",
    "        if out_ix > len(sequence):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "indian-mayor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (5, 2)\n",
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n"
     ]
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-challenge",
   "metadata": {},
   "source": [
    "## Vector Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "weird-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output a vector directly that can be interpreted as a multi-step forecast (seen previously)\n",
    "\n",
    "n_features = 1\n",
    "\n",
    "# reshape into 3 dim\n",
    "X = X.reshape(X.shape[0], X.shape[1], n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "geological-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation=\"relu\"))\n",
    "model.add(Dense(n_steps_out))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "seven-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbabde9550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "pressing-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.411446 102.52533 ]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-dayton",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "preliminary-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "technological-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "educational-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "# define encoder model\n",
    "# output of the encoder is a fixed length vector that represents the model's interpretation of the sequence\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "\n",
    "# The decoder uses the output of the encoder as an input\n",
    "# First, the fixed-length output of the encoder is repeated, once for each requirend time step in the output sequence\n",
    "# repeat encoding\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "\n",
    "# define decoder model\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "\n",
    "# define model output\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "absolute-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape output\n",
    "y = y.reshape(y.shape[0], y.shape[1], n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "average-interpretation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbb4445cc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "informal-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 92.49516 ]\n",
      "  [102.108154]]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-nation",
   "metadata": {},
   "source": [
    "# Multivariate Multi-step LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-sector",
   "metadata": {},
   "source": [
    "## Multiple Input Multi-step Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "forward-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, cols] structure\n",
    "in_seq1 = in_seq1.reshape(in_seq1.shape[0], 1)\n",
    "in_seq2 = in_seq2.reshape(in_seq2.shape[0], 1)\n",
    "out_seq = out_seq.reshape(out_seq.shape[0], 1)\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "narrow-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_ix = end_ix + n_steps_out -1\n",
    "        \n",
    "        if out_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "parental-favor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 2) (6, 2)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [65 85]\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [ 85 105]\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [105 125]\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [125 145]\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [145 165]\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] [165 185]\n"
     ]
    }
   ],
   "source": [
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "reduced-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "beginning-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation=\"relu\"))\n",
    "model.add(Dense(n_steps_out))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "virtual-amendment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbb0f596a0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "constant-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187.24307 208.91602]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([[70, 75], [80, 85], [90, 95]])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-cambridge",
   "metadata": {},
   "source": [
    "## Multiple Parallel Input Multi-step Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cloudy-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, cols] structure\n",
    "in_seq1 = in_seq1.reshape(in_seq1.shape[0], 1)\n",
    "in_seq2 = in_seq2.reshape(in_seq2.shape[0], 1)\n",
    "out_seq = out_seq.reshape(out_seq.shape[0], 1)\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "balanced-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_ix = end_ix + n_steps_out\n",
    "        \n",
    "        if out_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "personalized-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3) (5, 2, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [[ 50  55 105]\n",
      " [ 60  65 125]]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [[ 60  65 125]\n",
      " [ 70  75 145]]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [[ 70  75 145]\n",
      " [ 80  85 165]]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [[ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sharp-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use Vector Output or Encoder-Decoder LSTM to model this problem\n",
    "n_features = X.shape[2]\n",
    "n_output = y.shape[1] * y.shape[2]\n",
    "\n",
    "y = y.reshape(y.shape[0], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "numeric-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model Output Vector LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation=\"relu\"))\n",
    "model.add(Dense(n_output))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "proved-perception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbbbc56470>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "facial-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 89.76642  95.25615 186.46371 100.38029 107.02497 208.14716]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "future-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model Encoder-Decoder LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", input_shape=(n_steps_in, n_features)))\n",
    "\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "\n",
    "model.add(LSTM(100, return_sequences=True, activation=\"relu\"))\n",
    "\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "frozen-waterproof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xcbbe6775f8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "veterinary-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 91.501945  95.53477  185.0618  ]\n",
      "  [101.03532  104.86024  206.37529 ]]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = np.array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-peninsula",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
